{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ccfca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee10b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_order = [\"DI\", \"DII\", \"DIII\", \"AVL\", \"AVF\", \"AVR\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "df_attributes=pd.read_csv(\"attributes.csv\")\n",
    "path_data = \"C:/Users/danih/OneDrive/Bureau/M2 MAPI3/Machine Learning/Projets/BIG_PROJECT\"\n",
    "\n",
    "df_goldStandard = pd.read_csv(f'{path_data}/data/data/annotations/gold_standard.csv')\n",
    "df_goldStandard.rename(columns={\"1dAVb\":\"Un_dAVb\"},inplace=True)\n",
    "\n",
    "df_card1= pd.read_csv(f'{path_data}/data/data/annotations/cardiologist1.csv')\n",
    "df_card1.rename(columns={\"1dAVb\":\"Und_AVb\"},inplace=True)\n",
    "\n",
    "df_card2= pd.read_csv(f'{path_data}/data/data/annotations/cardiologist2.csv')\n",
    "df_card2.rename(columns={\"1dAVb\":\"Und_AVb\"},inplace=True)\n",
    "\n",
    "df_dnn= pd.read_csv(f'{path_data}/data/data/annotations/dnn.csv')\n",
    "df_dnn.rename(columns={\"1dAVb\":\"Und_AVb\"},inplace=True)\n",
    "\n",
    "\n",
    "df_card_res= pd.read_csv(f'{path_data}/data/data/annotations/cardiology_residents.csv')\n",
    "df_card_res.rename(columns={\"1dAVb\":\"Und_AVb\"},inplace=True)\n",
    "\n",
    "df_emerg_res= pd.read_csv(f'{path_data}/data/data/annotations/emergency_residents.csv')\n",
    "df_emerg_res.rename(columns={\"1dAVb\":\"Un_dAVb\"},inplace=True)\n",
    "\n",
    "df_medical_students= pd.read_csv(f'{path_data}/data/data/annotations/medical_students.csv')\n",
    "df_medical_students.rename(columns={\"1dAVb\":\"Un_dAVb\"},inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_dnn.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# df=df_goldStandard.join(df_cardiologist1,lsuffix='_goldStandard', rsuffix='_card1').join(df_cardiologist2,\n",
    "#     rsuffix='card_2').join(df_dnn,rsuffix='_dnn').join(df_cardiology_residents,rsuffix='_card_res').join(\n",
    "#     df_emergency_residents,rsuffix='_emerg_res').join(df_medical_students,rsuffix='_med_stud').join(df_attributes)\n",
    "\n",
    "\n",
    "df_goldStandard['nb_abnormality'] =  df_goldStandard.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00431099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Un_dAVb</th>\n",
       "      <th>RBBB</th>\n",
       "      <th>LBBB</th>\n",
       "      <th>SB</th>\n",
       "      <th>AF</th>\n",
       "      <th>ST</th>\n",
       "      <th>nb_abnormality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Un_dAVb  RBBB  LBBB  SB  AF  ST  nb_abnormality\n",
       "0          0     0     0   0   0   0               0\n",
       "1          0     0     1   0   0   0               1\n",
       "2          0     0     0   0   0   0               0\n",
       "3          0     0     0   0   0   0               0\n",
       "4          0     0     0   0   0   0               0\n",
       "..       ...   ...   ...  ..  ..  ..             ...\n",
       "822        0     0     0   0   0   0               0\n",
       "823        0     0     0   0   0   0               0\n",
       "824        0     0     0   0   0   0               0\n",
       "825        0     0     0   0   0   0               0\n",
       "826        1     0     0   0   0   0               1\n",
       "\n",
       "[827 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goldStandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405ca65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 4096, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with h5py.File(f\"{path_data}/data/data/ecg_tracings.hdf5\", \"r\") as f:\n",
    "    x = np.array(f['tracings'])\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad681a",
   "metadata": {},
   "source": [
    "## Modèle pré-entrainé pour réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5007854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 4096, 12)]\n",
      "(None, 4096, 64)\n",
      "(None, 4096, 64)\n",
      "(None, 4096, 64)\n",
      "(None, 4096, 128)\n",
      "(None, 4096, 128)\n",
      "(None, 4096, 128)\n",
      "(None, 4096, 128)\n",
      "(None, 1024, 64)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 128)\n",
      "(None, 1024, 196)\n",
      "(None, 1024, 196)\n",
      "(None, 1024, 196)\n",
      "(None, 1024, 196)\n",
      "(None, 256, 128)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 196)\n",
      "(None, 256, 256)\n",
      "(None, 256, 256)\n",
      "(None, 256, 256)\n",
      "(None, 256, 256)\n",
      "(None, 64, 196)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 256)\n",
      "(None, 64, 320)\n",
      "(None, 64, 320)\n",
      "(None, 64, 320)\n",
      "(None, 64, 320)\n",
      "(None, 16, 256)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 16, 320)\n",
      "(None, 5120)\n",
      "(None, 6)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "signal (InputLayer)             [(None, 4096, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4096, 64)     12288       signal[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4096, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4096, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 128)    131072      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4096, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4096, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096, 128)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1024, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1024, 128)    262144      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1024, 128)    8192        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1024, 128)    0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024, 128)    512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1024, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1024, 196)    401408      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024, 196)    784         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1024, 196)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024, 196)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 256, 128)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 256, 196)     614656      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 256, 196)     25088       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 196)     0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 196)     784         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 196)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 196)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 256, 256)     802816      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 256)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 64, 196)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 256)      1048576     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 256)      50176       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 256)      0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 256)      1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 256)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 320)      1310720     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 320)      1280        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 320)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 320)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 16, 256)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 16, 320)      1638400     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 16, 320)      81920       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 320)      0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 320)      1280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 320)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 320)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5120)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 6)            30726       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,425,638\n",
      "Trainable params: 6,421,910\n",
      "Non-trainable params: 3,728\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = load_model(f\"{path_data}/model/model/model.hdf5\", compile=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a03665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 28s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x,verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bd68e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proba_1dAVb</th>\n",
       "      <th>Proba_RBBB</th>\n",
       "      <th>Proba_LBBB</th>\n",
       "      <th>Proba_SB</th>\n",
       "      <th>Proba_AF</th>\n",
       "      <th>Proba_ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.424320e-06</td>\n",
       "      <td>1.071004e-07</td>\n",
       "      <td>2.633703e-07</td>\n",
       "      <td>4.537750e-07</td>\n",
       "      <td>9.485395e-07</td>\n",
       "      <td>6.413525e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.889732e-02</td>\n",
       "      <td>2.006710e-03</td>\n",
       "      <td>3.177863e-01</td>\n",
       "      <td>2.827818e-05</td>\n",
       "      <td>4.834345e-02</td>\n",
       "      <td>3.205240e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>3.112853e-04</td>\n",
       "      <td>2.940376e-05</td>\n",
       "      <td>4.175250e-06</td>\n",
       "      <td>1.971315e-05</td>\n",
       "      <td>9.349018e-03</td>\n",
       "      <td>2.493309e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.396912e-09</td>\n",
       "      <td>1.734494e-09</td>\n",
       "      <td>6.939355e-10</td>\n",
       "      <td>8.173876e-10</td>\n",
       "      <td>5.682145e-09</td>\n",
       "      <td>2.767275e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>5.306005e-04</td>\n",
       "      <td>3.533459e-06</td>\n",
       "      <td>3.394174e-07</td>\n",
       "      <td>1.430142e-06</td>\n",
       "      <td>2.242625e-04</td>\n",
       "      <td>4.707765e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822.0</th>\n",
       "      <td>2.662169e-06</td>\n",
       "      <td>2.271635e-07</td>\n",
       "      <td>1.546323e-07</td>\n",
       "      <td>1.969674e-07</td>\n",
       "      <td>1.191892e-05</td>\n",
       "      <td>3.100990e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823.0</th>\n",
       "      <td>4.383028e-04</td>\n",
       "      <td>1.032207e-05</td>\n",
       "      <td>1.012705e-04</td>\n",
       "      <td>4.085054e-08</td>\n",
       "      <td>8.352697e-04</td>\n",
       "      <td>6.998936e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824.0</th>\n",
       "      <td>6.078317e-07</td>\n",
       "      <td>3.985351e-08</td>\n",
       "      <td>1.985758e-08</td>\n",
       "      <td>1.092500e-08</td>\n",
       "      <td>1.017582e-06</td>\n",
       "      <td>3.607297e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825.0</th>\n",
       "      <td>3.941979e-08</td>\n",
       "      <td>2.405508e-09</td>\n",
       "      <td>8.350511e-10</td>\n",
       "      <td>9.778340e-09</td>\n",
       "      <td>6.802806e-08</td>\n",
       "      <td>3.952344e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826.0</th>\n",
       "      <td>1.733206e-01</td>\n",
       "      <td>2.456665e-03</td>\n",
       "      <td>8.600608e-05</td>\n",
       "      <td>4.635297e-05</td>\n",
       "      <td>2.052367e-03</td>\n",
       "      <td>7.277382e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Proba_1dAVb    Proba_RBBB    Proba_LBBB      Proba_SB      Proba_AF  \\\n",
       "0.0    1.424320e-06  1.071004e-07  2.633703e-07  4.537750e-07  9.485395e-07   \n",
       "1.0    2.889732e-02  2.006710e-03  3.177863e-01  2.827818e-05  4.834345e-02   \n",
       "2.0    3.112853e-04  2.940376e-05  4.175250e-06  1.971315e-05  9.349018e-03   \n",
       "3.0    2.396912e-09  1.734494e-09  6.939355e-10  8.173876e-10  5.682145e-09   \n",
       "4.0    5.306005e-04  3.533459e-06  3.394174e-07  1.430142e-06  2.242625e-04   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "822.0  2.662169e-06  2.271635e-07  1.546323e-07  1.969674e-07  1.191892e-05   \n",
       "823.0  4.383028e-04  1.032207e-05  1.012705e-04  4.085054e-08  8.352697e-04   \n",
       "824.0  6.078317e-07  3.985351e-08  1.985758e-08  1.092500e-08  1.017582e-06   \n",
       "825.0  3.941979e-08  2.405508e-09  8.350511e-10  9.778340e-09  6.802806e-08   \n",
       "826.0  1.733206e-01  2.456665e-03  8.600608e-05  4.635297e-05  2.052367e-03   \n",
       "\n",
       "           Proba_ST  \n",
       "0.0    6.413525e-09  \n",
       "1.0    3.205240e-04  \n",
       "2.0    2.493309e-05  \n",
       "3.0    2.767275e-10  \n",
       "4.0    4.707765e-06  \n",
       "...             ...  \n",
       "822.0  3.100990e-08  \n",
       "823.0  6.998936e-07  \n",
       "824.0  3.607297e-08  \n",
       "825.0  3.952344e-09  \n",
       "826.0  7.277382e-05  \n",
       "\n",
       "[827 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.linspace(0,826,827)\n",
    "\n",
    "df_pred = pd.DataFrame(y_pred, index = ind,columns=['Proba_1dAVb','Proba_RBBB','Proba_LBBB','Proba_SB','Proba_AF','Proba_ST'])\n",
    "\n",
    "display(df_pred)    #prédictions du réseau de neurones sur le modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c08609",
   "metadata": {},
   "source": [
    "## Précisions des différents étudiants/médecins par rapport au gold standard\n",
    "On compare le nombre d'anomalies prédites par les différents étudiants/médecins par rapport au gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "408a0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39fd37b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pourcentage de patient ayant aucune anomalie 82.34582829504232\n",
      "pourcentage de patient ayant 1 anomalie 16.203143893591292\n",
      "pourcentage de patient ayant 2 anomalies 1.4510278113663846\n",
      "pourcentage de patient ayant + de 2 anomalies 0.0\n"
     ]
    }
   ],
   "source": [
    "y_true = df_goldStandard['nb_abnormality']\n",
    "\n",
    "\n",
    "print('pourcentage de patient ayant aucune anomalie',len(y_true[y_true==0])/len(y_true)*100)\n",
    "print('pourcentage de patient ayant 1 anomalie',len(y_true[y_true==1])/len(y_true)*100)\n",
    "print('pourcentage de patient ayant 2 anomalies',len(y_true[y_true==2])/len(y_true)*100)\n",
    "print('pourcentage de patient ayant + de 2 anomalies',len(y_true[y_true>2])/len(y_true)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf45bdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score du cardiologist 1= 0.9654864414968609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[674,   7,   0],\n",
       "       [ 19, 114,   1],\n",
       "       [  0,   1,  11]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred_card1=df_card1.sum(axis=1)\n",
    "\n",
    "\n",
    "print('F1 score du cardiologist 1=', f1_score(y_true,y_pred_card1,average='weighted'))\n",
    "confusion_matrix(y_true,y_pred_card1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daaf0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score du cardiologist 2= 0.9804184976636632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[677,   3,   1],\n",
       "       [ 12, 122,   0],\n",
       "       [  0,   0,  12]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_card2=df_card2.sum(a\n",
    "\n",
    "print('F1 score du cardiologist 2=', f1_score(y_true,y_pred_card2,average='weighted'))\n",
    "confusion_matrix(y_true,y_pred_card2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4ab5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score du réseau de neurones= 0.9763569011176221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[674,   7,   0],\n",
       "       [  6, 122,   6],\n",
       "       [  0,   1,  11]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dnn=df_dnn.sum(axis=1)\n",
    "\n",
    "\n",
    "print('F1 score du réseau de neurones=', f1_score(y_true,y_pred_dnn,average='weighted'))\n",
    "confusion_matrix(y_true,y_pred_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0029d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score des 2 résidents en cardiologie= 0.959424594726542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[672,   9,   0],\n",
       "       [ 17, 114,   3],\n",
       "       [  1,   3,   8]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_card_res=df_card_res.sum(axis=1)\n",
    "\n",
    "\n",
    "print('F1 score des 2 résidents en cardiologie=', f1_score(y_true,y_pred_card_res,average='weighted'))\n",
    "confusion_matrix(y_true,y_pred_card_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c73c3a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score des 2 urgentistes résidents= 0.9525956775606055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[664,  17,   0],\n",
       "       [ 17, 115,   2],\n",
       "       [  3,   0,   9]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_emerg_res=df_emerg_res.sum(axis=1)\n",
    "\n",
    "\n",
    "print('F1 score des 2 urgentistes résidents=', f1_score(y_true,y_pred_emerg_res,average='weighted'))\n",
    "confusion_matrix(y_true,y_pred_emerg_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "629c0a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score des 2 étudiants en médecine= 0.9460800081880871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[664,  13,   4,   0],\n",
       "       [ 13, 106,  14,   1],\n",
       "       [  1,   2,   9,   0],\n",
       "       [  0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_med_stud=df_medical_students.sum(axis=1)\n",
    "\n",
    "\n",
    "print('F1 score des 2 étudiants en médecine=', f1_score(y_true,y_pred_med_stud,average='weighted'))\n",
    "confusion_matrix(y_true,y_pred_med_stud)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2459eb7",
   "metadata": {},
   "source": [
    "## Apprentissage supervisé\n",
    "\n",
    "On peut également entraîner des classifieurs SVC, LogisticRegression, RandomForest pour comparer les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "680e4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe8719a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49142</th>\n",
       "      <th>49143</th>\n",
       "      <th>49144</th>\n",
       "      <th>49145</th>\n",
       "      <th>49146</th>\n",
       "      <th>49147</th>\n",
       "      <th>49148</th>\n",
       "      <th>49149</th>\n",
       "      <th>49150</th>\n",
       "      <th>49151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407469</td>\n",
       "      <td>-0.397223</td>\n",
       "      <td>0.211611</td>\n",
       "      <td>0.178307</td>\n",
       "      <td>1.942285</td>\n",
       "      <td>2.809755</td>\n",
       "      <td>1.25819</td>\n",
       "      <td>1.202997</td>\n",
       "      <td>1.659529</td>\n",
       "      <td>-0.759827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "      49142     49143     49144     49145     49146     49147    49148  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "1  0.407469 -0.397223  0.211611  0.178307  1.942285  2.809755  1.25819   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "\n",
       "      49149     49150     49151  \n",
       "0  0.000000  0.000000  0.000000  \n",
       "1  1.202997  1.659529 -0.759827  \n",
       "2  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 49152 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx, dy, dz = x.shape                     #On redimensionne les données d'entrainement X\n",
    "\n",
    "X = x.reshape(dx, dy * dz)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a7c3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y_true, train_size = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b6bf132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49142</th>\n",
       "      <th>49143</th>\n",
       "      <th>49144</th>\n",
       "      <th>49145</th>\n",
       "      <th>49146</th>\n",
       "      <th>49147</th>\n",
       "      <th>49148</th>\n",
       "      <th>49149</th>\n",
       "      <th>49150</th>\n",
       "      <th>49151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 49152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7      8      9      \\\n",
       "103    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "387    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "336    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "284    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "800    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "341    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "290    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "742    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "436    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "243    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     ...  49142  49143  49144  49145  49146  49147  49148  49149  49150  49151  \n",
       "103  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "387  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "336  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "284  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "800  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "341  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "290  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "742  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "436  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "243  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[661 rows x 49152 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "117c2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "# On normalise les données \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "Xr_train = scaler.transform(X_train)  \n",
    "# Meme transformation sur le test\n",
    "Xr_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39598fee",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b295cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Lasso conserve 202 variables et en supprime 48950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "49147    0.0\n",
       "49148    0.0\n",
       "49149    0.0\n",
       "49150    0.0\n",
       "49151    0.0\n",
       "Length: 49152, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=0.2\n",
    "Classifier1 = LogisticRegression(penalty=\"l1\",C=C,\n",
    "                              solver=\"liblinear\")\n",
    "\n",
    "logitCoef=Classifier1.fit(Xr_train,y_train).coef_\n",
    "print(logitCoef)\n",
    "\n",
    "coef = pd.Series(logitCoef[0], index = X_train.columns)\n",
    "print(\"Lasso conserve \" + str(sum(coef != 0)) + \n",
    "      \" variables et en supprime \" +  str(sum(coef == 0)))\n",
    "\n",
    "coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7f5953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Lasso conserve 874 variables et en supprime 48278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "49147    0.0\n",
       "49148    0.0\n",
       "49149    0.0\n",
       "49150    0.0\n",
       "49151    0.0\n",
       "Length: 49152, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=5\n",
    "Classifier1 = LogisticRegression(penalty=\"l1\",C=C,\n",
    "                              solver=\"liblinear\")\n",
    "\n",
    "logitCoef=Classifier1.fit(Xr_train,y_train).coef_\n",
    "print(logitCoef)\n",
    "\n",
    "coef = pd.Series(logitCoef[0], index = X_train.columns)\n",
    "print(\"Lasso conserve \" + str(sum(coef != 0)) + \n",
    "      \" variables et en supprime \" +  str(sum(coef == 0)))\n",
    "\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48bc94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Lasso conserve 3012 variables et en supprime 46140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "        ... \n",
       "49147    0.0\n",
       "49148    0.0\n",
       "49149    0.0\n",
       "49150    0.0\n",
       "49151    0.0\n",
       "Length: 49152, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=100\n",
    "Classifier1 = LogisticRegression(penalty=\"l1\",C=C,\n",
    "                              solver=\"liblinear\")\n",
    "\n",
    "logitCoef=Classifier1.fit(Xr_train,y_train).coef_\n",
    "print(logitCoef)\n",
    "\n",
    "coef = pd.Series(logitCoef[0], index = X_train.columns)\n",
    "print(\"Lasso conserve \" + str(sum(coef != 0)) + \n",
    "      \" variables et en supprime \" +  str(sum(coef == 0)))\n",
    "\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3def1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur score = 0.192139, Meilleur paramètre = {'C': 0.2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Optimisation du paramètre de pénalisation\n",
    "# grille de valeurs\n",
    "param=[{\"C\":[0.2, 1,10,30,50,100]}]\n",
    "logit = GridSearchCV(LogisticRegression(penalty=\"l1\", solver = \"liblinear\"), param,cv=5,n_jobs=-1)\n",
    "logitOpt=logit.fit(Xr_train, y_train)\n",
    "# paramètre optimal\n",
    "# paramètre optimal\n",
    "\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1.-logitOpt.best_score_,logitOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e57a978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danih\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    }
   ],
   "source": [
    "C=logitOpt.best_params_[\"C\"]                #best logistic regression model                             \n",
    "typePenal=\"l1\"\n",
    "nproc=-1\n",
    "logit = LogisticRegression(penalty=typePenal, dual=False, tol=0.0001, \n",
    "            C=C, fit_intercept=True, intercept_scaling=1, \n",
    "            class_weight=None, random_state=None, solver='liblinear', \n",
    "            max_iter=100, multi_class='ovr', verbose=0, \n",
    "            warm_start=False, n_jobs=nproc)\n",
    "logitFit=logit.fit(Xr_train, y_train)\n",
    "y_logit_pred = logitFit.predict(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "809bd1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score de la regression logistique= 0.7890130378499697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[138,   4,   0],\n",
       "       [ 21,   1,   0],\n",
       "       [  2,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On mesure le score sur les données test\n",
    "\n",
    "\n",
    "print('F1 score de la regression logistique=', f1_score(y_test,y_logit_pred,average='weighted'))\n",
    "confusion_matrix(y_test,y_logit_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309c6ed",
   "metadata": {},
   "source": [
    "Il semblerait que ce modèle ne parvienne pas à correctement identifier les patients ayant des anomalies, il prédit 97% des patients comme ayant aucune anomalie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05490188",
   "metadata": {},
   "source": [
    "## SupportVectorClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aa170d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danih\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state = 0)\n",
    "svc.fit(Xr_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f4b1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svc_pred = svc.predict(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aa900341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score du linearSVC= 0.7424134948249907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[118,  23,   1],\n",
       "       [ 17,   3,   2],\n",
       "       [  1,   1,   0]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On mesure le score sur les données test\n",
    "\n",
    "print('F1 score du linearSVC=', f1_score(y_test,y_svc_pred,average='weighted'))\n",
    "confusion_matrix(y_test,y_svc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538fb9c",
   "metadata": {},
   "source": [
    "Ici aussi, le modèle semble avoir du mal à bien prédire les anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fac8a",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "96fc7f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(random_state = 0)\n",
    "RF.fit(Xr_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c2cfd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_RF_pred = RF.predict(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12be686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score du RFC= 0.8015168872210151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[141,   1,   0],\n",
       "       [ 21,   1,   0],\n",
       "       [  1,   1,   0]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On mesure le score sur les données test\n",
    "\n",
    "print('F1 score du RFC=', f1_score(y_test,y_RF_pred,average='weighted'))\n",
    "confusion_matrix(y_test,y_RF_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376b58b",
   "metadata": {},
   "source": [
    "Encore une fois le modèle ne prédit presque jamais qu'un patient a une anomalie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db889156",
   "metadata": {},
   "source": [
    "**Conclusion :** Il semblerait que les classifieurs classiques pour l'apprentissage supervisé ne soient pas performants pour prédire quand un patient est atteint d'une anomalie.\n",
    "Peut-être faut-il jouer sur les paramètres pour obtenir de meilleures prédictions?\n",
    "Peut-être qu'on peut effectuer une ACP pour éliminer les variables inutiles ? Peut-être qu'un clustering sera plus efficace ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1a960",
   "metadata": {},
   "source": [
    "# ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a86874cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df_goldStandard.corr())   #Corrélation entre les anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd9b93",
   "metadata": {},
   "source": [
    "Il semblerait que les anomalies soient relativement peu corrélées entres elles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a26e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bf5cf84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13a5f15c7c0>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PCA()\n",
    "X_reduced= model.fit_transform(X)\n",
    "plt.plot(np.cumsum(model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b4791d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(827, 827)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c024b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.cumsum(model.explained_variance_ratio_) > 0.99)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3849b9",
   "metadata": {},
   "source": [
    "On garde 99% de la variance avec seulement 425 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56f28c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>817</th>\n",
       "      <th>818</th>\n",
       "      <th>819</th>\n",
       "      <th>820</th>\n",
       "      <th>821</th>\n",
       "      <th>822</th>\n",
       "      <th>823</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "      <th>826</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.302910</td>\n",
       "      <td>13.115261</td>\n",
       "      <td>3.070312</td>\n",
       "      <td>1.609468</td>\n",
       "      <td>-1.528234</td>\n",
       "      <td>-1.144516</td>\n",
       "      <td>0.086531</td>\n",
       "      <td>-0.683829</td>\n",
       "      <td>1.335477</td>\n",
       "      <td>-2.414057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064021</td>\n",
       "      <td>-0.109689</td>\n",
       "      <td>-0.046761</td>\n",
       "      <td>0.516789</td>\n",
       "      <td>0.228357</td>\n",
       "      <td>0.111523</td>\n",
       "      <td>0.136346</td>\n",
       "      <td>-0.259369</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-24.292273</td>\n",
       "      <td>162.766072</td>\n",
       "      <td>-37.109720</td>\n",
       "      <td>87.372886</td>\n",
       "      <td>-4.320288</td>\n",
       "      <td>-118.867879</td>\n",
       "      <td>-69.213111</td>\n",
       "      <td>10.222081</td>\n",
       "      <td>10.224597</td>\n",
       "      <td>8.196486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046172</td>\n",
       "      <td>-0.138531</td>\n",
       "      <td>0.031055</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>0.025131</td>\n",
       "      <td>0.229335</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>-0.005385</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.162659</td>\n",
       "      <td>12.885106</td>\n",
       "      <td>2.472807</td>\n",
       "      <td>0.899353</td>\n",
       "      <td>-0.493598</td>\n",
       "      <td>-0.905827</td>\n",
       "      <td>-0.441227</td>\n",
       "      <td>-2.047665</td>\n",
       "      <td>-1.266835</td>\n",
       "      <td>0.153921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791928</td>\n",
       "      <td>-0.572866</td>\n",
       "      <td>-0.326748</td>\n",
       "      <td>-0.742220</td>\n",
       "      <td>0.553856</td>\n",
       "      <td>1.051031</td>\n",
       "      <td>0.228749</td>\n",
       "      <td>0.290152</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.436321</td>\n",
       "      <td>12.621942</td>\n",
       "      <td>3.044800</td>\n",
       "      <td>1.420967</td>\n",
       "      <td>-1.364358</td>\n",
       "      <td>-0.969433</td>\n",
       "      <td>-0.460491</td>\n",
       "      <td>-2.065014</td>\n",
       "      <td>-0.168198</td>\n",
       "      <td>-1.568945</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.151660</td>\n",
       "      <td>0.057781</td>\n",
       "      <td>0.285725</td>\n",
       "      <td>0.559163</td>\n",
       "      <td>0.355292</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.331360</td>\n",
       "      <td>-0.405980</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.319026</td>\n",
       "      <td>13.231013</td>\n",
       "      <td>2.433977</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>-1.201106</td>\n",
       "      <td>-1.223011</td>\n",
       "      <td>-0.204855</td>\n",
       "      <td>-1.593515</td>\n",
       "      <td>-0.667685</td>\n",
       "      <td>-0.410360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.704623</td>\n",
       "      <td>0.307943</td>\n",
       "      <td>0.606673</td>\n",
       "      <td>-0.590142</td>\n",
       "      <td>-0.428777</td>\n",
       "      <td>0.014704</td>\n",
       "      <td>0.075435</td>\n",
       "      <td>-0.004936</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>-8.375343</td>\n",
       "      <td>13.601525</td>\n",
       "      <td>2.427110</td>\n",
       "      <td>1.246592</td>\n",
       "      <td>-1.504467</td>\n",
       "      <td>-0.377082</td>\n",
       "      <td>-0.398361</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>1.990470</td>\n",
       "      <td>0.416474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793367</td>\n",
       "      <td>-0.321626</td>\n",
       "      <td>-0.629262</td>\n",
       "      <td>0.798691</td>\n",
       "      <td>-0.209335</td>\n",
       "      <td>1.124360</td>\n",
       "      <td>-0.048739</td>\n",
       "      <td>-0.595422</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-7.816766</td>\n",
       "      <td>12.762692</td>\n",
       "      <td>2.235708</td>\n",
       "      <td>0.911167</td>\n",
       "      <td>-1.028325</td>\n",
       "      <td>-0.958366</td>\n",
       "      <td>-0.116489</td>\n",
       "      <td>-0.246163</td>\n",
       "      <td>0.038225</td>\n",
       "      <td>1.044430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046719</td>\n",
       "      <td>0.029748</td>\n",
       "      <td>-0.244456</td>\n",
       "      <td>0.073355</td>\n",
       "      <td>-0.187164</td>\n",
       "      <td>0.063603</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>0.145744</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>-7.757031</td>\n",
       "      <td>13.473473</td>\n",
       "      <td>2.072325</td>\n",
       "      <td>-0.044633</td>\n",
       "      <td>-1.734136</td>\n",
       "      <td>-1.330659</td>\n",
       "      <td>-0.143922</td>\n",
       "      <td>-1.720592</td>\n",
       "      <td>-1.114519</td>\n",
       "      <td>-0.401865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>0.038604</td>\n",
       "      <td>-0.099884</td>\n",
       "      <td>0.054667</td>\n",
       "      <td>-0.002805</td>\n",
       "      <td>-0.060626</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>0.318818</td>\n",
       "      <td>-0.003586</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-8.329909</td>\n",
       "      <td>13.337693</td>\n",
       "      <td>2.535648</td>\n",
       "      <td>0.801219</td>\n",
       "      <td>-1.123718</td>\n",
       "      <td>-1.119133</td>\n",
       "      <td>-0.285502</td>\n",
       "      <td>-1.809556</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>0.069577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216825</td>\n",
       "      <td>-0.627946</td>\n",
       "      <td>0.150703</td>\n",
       "      <td>0.196883</td>\n",
       "      <td>0.162514</td>\n",
       "      <td>0.338568</td>\n",
       "      <td>-0.370584</td>\n",
       "      <td>-1.067648</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-8.693868</td>\n",
       "      <td>13.667386</td>\n",
       "      <td>2.510956</td>\n",
       "      <td>1.101244</td>\n",
       "      <td>-1.271608</td>\n",
       "      <td>-1.286158</td>\n",
       "      <td>-0.774485</td>\n",
       "      <td>-2.293560</td>\n",
       "      <td>-1.240983</td>\n",
       "      <td>-0.879552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206289</td>\n",
       "      <td>-0.237321</td>\n",
       "      <td>0.093226</td>\n",
       "      <td>-0.196630</td>\n",
       "      <td>0.309669</td>\n",
       "      <td>-0.125919</td>\n",
       "      <td>-0.132612</td>\n",
       "      <td>-0.111693</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>1.332275e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3         4           5    \\\n",
       "0    -8.302910   13.115261   3.070312   1.609468 -1.528234   -1.144516   \n",
       "1   -24.292273  162.766072 -37.109720  87.372886 -4.320288 -118.867879   \n",
       "2    -8.162659   12.885106   2.472807   0.899353 -0.493598   -0.905827   \n",
       "3    -8.436321   12.621942   3.044800   1.420967 -1.364358   -0.969433   \n",
       "4    -8.319026   13.231013   2.433977   1.000133 -1.201106   -1.223011   \n",
       "..         ...         ...        ...        ...       ...         ...   \n",
       "822  -8.375343   13.601525   2.427110   1.246592 -1.504467   -0.377082   \n",
       "823  -7.816766   12.762692   2.235708   0.911167 -1.028325   -0.958366   \n",
       "824  -7.757031   13.473473   2.072325  -0.044633 -1.734136   -1.330659   \n",
       "825  -8.329909   13.337693   2.535648   0.801219 -1.123718   -1.119133   \n",
       "826  -8.693868   13.667386   2.510956   1.101244 -1.271608   -1.286158   \n",
       "\n",
       "           6          7          8         9    ...       817       818  \\\n",
       "0     0.086531  -0.683829   1.335477 -2.414057  ... -0.064021 -0.109689   \n",
       "1   -69.213111  10.222081  10.224597  8.196486  ... -0.046172 -0.138531   \n",
       "2    -0.441227  -2.047665  -1.266835  0.153921  ...  0.791928 -0.572866   \n",
       "3    -0.460491  -2.065014  -0.168198 -1.568945  ... -1.151660  0.057781   \n",
       "4    -0.204855  -1.593515  -0.667685 -0.410360  ...  0.577982  0.704623   \n",
       "..         ...        ...        ...       ...  ...       ...       ...   \n",
       "822  -0.398361   0.044343   1.990470  0.416474  ...  0.793367 -0.321626   \n",
       "823  -0.116489  -0.246163   0.038225  1.044430  ...  0.046719  0.029748   \n",
       "824  -0.143922  -1.720592  -1.114519 -0.401865  ...  0.061034  0.038604   \n",
       "825  -0.285502  -1.809556   0.015952  0.069577  ... -0.216825 -0.627946   \n",
       "826  -0.774485  -2.293560  -1.240983 -0.879552  ...  0.206289 -0.237321   \n",
       "\n",
       "          819       820       821       822       823       824       825  \\\n",
       "0   -0.046761  0.516789  0.228357  0.111523  0.136346 -0.259369  0.000940   \n",
       "1    0.031055  0.011751  0.025131  0.229335  0.132184 -0.005385 -0.000115   \n",
       "2   -0.326748 -0.742220  0.553856  1.051031  0.228749  0.290152 -0.002395   \n",
       "3    0.285725  0.559163  0.355292  0.068300  0.331360 -0.405980  0.001709   \n",
       "4    0.307943  0.606673 -0.590142 -0.428777  0.014704  0.075435 -0.004936   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "822 -0.629262  0.798691 -0.209335  1.124360 -0.048739 -0.595422 -0.004466   \n",
       "823 -0.244456  0.073355 -0.187164  0.063603 -0.026707  0.145744 -0.000592   \n",
       "824 -0.099884  0.054667 -0.002805 -0.060626  0.126126  0.318818 -0.003586   \n",
       "825  0.150703  0.196883  0.162514  0.338568 -0.370584 -1.067648  0.001292   \n",
       "826  0.093226 -0.196630  0.309669 -0.125919 -0.132612 -0.111693 -0.001132   \n",
       "\n",
       "              826  \n",
       "0    1.332275e-14  \n",
       "1    1.332275e-14  \n",
       "2    1.332275e-14  \n",
       "3    1.332275e-14  \n",
       "4    1.332275e-14  \n",
       "..            ...  \n",
       "822  1.332275e-14  \n",
       "823  1.332275e-14  \n",
       "824  1.332275e-14  \n",
       "825  1.332275e-14  \n",
       "826  1.332275e-14  \n",
       "\n",
       "[827 rows x 827 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = pd.DataFrame(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f89761",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "498b70e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7497b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans (n_clusters = 3)   #3 classes 0, 1 et 2\n",
    "\n",
    "y_cluster_pred =kmeans.fit_predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0286efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score du Clustering= 0.7195446459912288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[595,  66,  20],\n",
       "       [116,  14,   4],\n",
       "       [ 11,   1,   0]], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On mesure le score sur les données test\n",
    "\n",
    "print('F1 score du Clustering=', f1_score(y_true,y_cluster_pred,average='weighted'))\n",
    "confusion_matrix(y_true,y_cluster_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b42f5b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c644d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eeec77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316eb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00446b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554668f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb3b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a7e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0032c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde9da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd36a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56e778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b0fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629538d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce1e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c5b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6080ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b3000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ccf658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f43d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b29a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2301b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3cd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b0535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d85a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4eb120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e90e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4a910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2c104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4e220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c328b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cacde26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a985806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56c1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd9ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
